{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalitpandey02/PythonNotebooks/blob/main/Seq2Seq_Model_for_Machine_Translation_(Practical).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFTryGBIwWMy"
      },
      "source": [
        "<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"100\" /></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRfn02fTwWM0"
      },
      "source": [
        "# <center><h1>Seq2Seq Model for Neural Machine Translation</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHqqzEjJajvw"
      },
      "source": [
        "\n",
        "---\n",
        "# **Table of Contents**\n",
        "---\n",
        "\n",
        "**1.** [**Introduction to Seq2Seq Model**](#Section1)<br>\n",
        "**2.** [**Problem Description**](#Section2)<br>\n",
        "**3.** [**Installing & Importing Libraries**](#Section3)<br>\n",
        "**4.** [**Data Acquisition & Description**](#Section4)<br>\n",
        "**5.** [**Data Preprocessing**](#Section5)<br>\n",
        "**6.** [**Machine Translation Model**](#Section6)<br>\n",
        "  - **6.1** [**Define Encoder Model**](#Section61)\n",
        "  - **6.2** [**Define Decoder Model**](#Section62) \n",
        "  - **6.3** [**Model Training**](#Section63)\n",
        "  - **6.4** [**Inference Model**](#Section61)\n",
        "  - **6.5** [**Making Predictions**](#Section62)\n",
        "\n",
        "**7.** [**Conclusion**](#Section7)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jakTEOLgw9Uu"
      },
      "source": [
        "---\n",
        "<a name = Section1></a>\n",
        "# **1. Introduction to Seq2seq model**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82vXHKnawWM2"
      },
      "source": [
        "- The **encoder-decoder model** provides a pattern for using **recurrent neural networks** to address challenging **sequence-to-sequence** prediction problems, such as **machine translation**.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/encoder_decoder4.png\"width=\"600\" height=\"230\"/></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/encoder_decoder5.png\"width=\"900\" height=\"500\"/></center>\n",
        "\n",
        "\n",
        "<br>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8keR31HheoR"
      },
      "source": [
        "\n",
        "- **Sequence to Sequence** models are a special **class** of **Recurrent Neural** Network architectures typically used (but not restricted) to **solve** complex **Language** related problems like **Machine Translation**, **Question** **Answering**, creating **Chat-bots**, **Text Summarization**, etc.\n",
        "\n",
        "- Sequence-to-Sequence (Seq2Seq) modelling is about **training** the models that can **convert** sequences from one **domain** to sequences of another **domain**, for example, English to French **Language Transaltion**.\n",
        "\n",
        "- Encoder-decoder is the **standard** modeling **paradigm** for sequence-to-sequence tasks. This **framework** consists of two **components**:\n",
        "\n",
        "  - **Encoder** - Reads **source sequence** and **produces** its representation;\n",
        "  - **Decoder** - Uses **source representation** from the **encoder** to generate the **target** sequence.\n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/s2s_data/SS10.gif\"width=\"600\" height=\"300\"/></center>\n",
        "\n",
        "<br>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_9j87w-EUN0"
      },
      "source": [
        "---\n",
        "<a name = Section2></a>\n",
        "# **2. Problem Statement**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diPfl1A2eX-i"
      },
      "source": [
        "- The most popular **sequence-to-sequence** task is **translation**. Usually, from **one** natural language to **another**. \n",
        "\n",
        "- In the last couple of years, **commercial systems** became surprisingly **good** at **machine translation** for example, **Google Translate**, **Yandex** **Translate**, **DeepL Translator**, **Bing Microsoft Translator**. \n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/s2s_data/ss12.png\"width=\"690\" height=\"350\"/></center>\n",
        "\n",
        "<br>  \n",
        "- In the **machine translation** task, we have an **input** sequence\n",
        "and an **output** sequence. Translation can be **thought** of as finding the **target** sequence that is the most **probable** given the **input**.\n",
        "\n",
        "- Formally, the **target** sequence that **maximizes** the conditional **probability** for next **output**.\n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/s2s_data/ss22.png\"width=\"690\" height=\"300\"/></center>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOmVgY8yWE36"
      },
      "source": [
        "---\n",
        "<a name = Section3></a>\n",
        "# **3. Installing and Importing Libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzYxZ6aMNLIQ",
        "outputId": "d8993c62-2861-4271-c937-56c499d6a405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Checking whether GPU is available or not, to be used with tensorflow.\n",
        "import tensorflow as tf \n",
        "device_name = tf.test.gpu_device_name() \n",
        "if device_name != '/device:GPU:0': raise SystemError('GPU device not found') \n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BzSZq3xgF1vB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLC-KEeGwWM7"
      },
      "source": [
        "- The **dataset** used in the example involves short **Spanish** and **English** sentence **pairs**.\n",
        "\n",
        "- The dataset is called **Tab-delimited Bilingual Sentence Pairs** and is part of the **Tatoeba Project** and listed on the **ManyThings.org** site for helping English as a Second Language students.\n",
        "\n",
        "- The problem is framed as a **sequence prediction problem** where input sequences of characters are in **English** and output sequences of characters are in **Spanish**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GPcHMD3nwWM8"
      },
      "outputs": [],
      "source": [
        "# Importing the dataset from github.\n",
        "\n",
        "response = urllib.request.urlopen('https://raw.githubusercontent.com/insaid2018/DeepLearning/master/Data/spa.txt')\n",
        "lines = response.readlines()\n",
        "\n",
        "text = []\n",
        "for sent in lines:\n",
        "    text.append(sent.decode('utf8'))\n",
        "    \n",
        "lines = text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1g09RUxwWND",
        "outputId": "d86c6220-c8c8-4da4-9744-8c7a56a1e4b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVe.\n",
            "\n",
            "Go.\tVete.\n",
            "\n",
            "Go.\tVaya.\n",
            "\n",
            "Put it on.\tPónganselo.\n",
            "\n",
            "Come early.\tVen temprano.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checking a few samples from the dataset.\n",
        "print(lines[0])\n",
        "print(lines[1])\n",
        "print(lines[2])\n",
        "print(lines[800])\n",
        "print(lines[1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrH4xgKawWNA",
        "outputId": "8ef84a58-c701-4d95-91f5-72ef33b438bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "type(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXsm6R0RwWNG",
        "outputId": "53537b16-0b2c-4f7b-a3eb-a0b09d7c395b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123376"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Checking the number of samples in the dataset.\n",
        "len(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lszB-fmkWW4f"
      },
      "source": [
        "---\n",
        "<a name = Section5></a>\n",
        "# **5. Data Preprocessing**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pljKFiz72FZ4"
      },
      "outputs": [],
      "source": [
        "batch_size = 32           # Batch size for training.\n",
        "epochs = 100              # Number of epochs to train for.\n",
        "latent_dim = 256          # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000       # Number of samples to train on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFbfkJaBMmEm"
      },
      "source": [
        "- **Vectorizing** the **data**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U5gT9lWr2FcX"
      },
      "outputs": [],
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p89ZyKwuMmEs"
      },
      "source": [
        "- Creating two list input_texts and target_texts containing **all** the **inputs** and **targets**.\n",
        "\n",
        "- Creating two sets **input_characters** and **target_characters** containing the **unique** characters **present** in the input and the target respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sb1A5DpfwWNK"
      },
      "outputs": [],
      "source": [
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    \n",
        "    # We use \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    \n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    \n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    \n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLpjjuzMmEw"
      },
      "source": [
        "- Converting the sets **`input_characters`** and **`target_characters`** into **lists** and **sorting** them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1tTog-RHMmEx"
      },
      "outputs": [],
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejnTFTT5MmE0"
      },
      "source": [
        "- Creating variables **`num_encoder_tokens`** and **`num_decoder_tokens`** having value equal to the number of **unique** values present in the sets **input_characters** and **target_characters** respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uC5Q-tL9MmE0"
      },
      "outputs": [],
      "source": [
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "83ym878K2Fez"
      },
      "outputs": [],
      "source": [
        "### Creating variables max_encoder_seq_length and max_decoder_seq_length having values equal to the length of longest sequences present in the input and the target respectively.\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmG40PNK2MXu",
        "outputId": "efdb2b8c-c0d6-403a-8c9c-98d3b2eef217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 69\n",
            "Number of unique output tokens: 85\n",
            "Max sequence length for inputs: 16\n",
            "Max sequence length for outputs: 43\n"
          ]
        }
      ],
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MbXTKWaIwWNN"
      },
      "outputs": [],
      "source": [
        "\"\"\"Creating dictionaries input_token_index and \n",
        "target_token_index which have unique characters present \n",
        "in the input and the target as keys and\n",
        " their position as the values respectively.\"\"\"\n",
        " \n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tojWIqwfwWNP",
        "outputId": "d95c5d93-c870-416e-a9f7-56cfcf01f415"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '$': 2,\n",
              " \"'\": 3,\n",
              " ',': 4,\n",
              " '-': 5,\n",
              " '.': 6,\n",
              " '0': 7,\n",
              " '1': 8,\n",
              " '2': 9,\n",
              " '3': 10,\n",
              " '4': 11,\n",
              " '5': 12,\n",
              " '6': 13,\n",
              " '7': 14,\n",
              " '8': 15,\n",
              " '9': 16,\n",
              " ':': 17,\n",
              " '?': 18,\n",
              " 'A': 19,\n",
              " 'B': 20,\n",
              " 'C': 21,\n",
              " 'D': 22,\n",
              " 'E': 23,\n",
              " 'F': 24,\n",
              " 'G': 25,\n",
              " 'H': 26,\n",
              " 'I': 27,\n",
              " 'J': 28,\n",
              " 'K': 29,\n",
              " 'L': 30,\n",
              " 'M': 31,\n",
              " 'N': 32,\n",
              " 'O': 33,\n",
              " 'P': 34,\n",
              " 'Q': 35,\n",
              " 'R': 36,\n",
              " 'S': 37,\n",
              " 'T': 38,\n",
              " 'U': 39,\n",
              " 'V': 40,\n",
              " 'W': 41,\n",
              " 'Y': 42,\n",
              " 'a': 43,\n",
              " 'b': 44,\n",
              " 'c': 45,\n",
              " 'd': 46,\n",
              " 'e': 47,\n",
              " 'f': 48,\n",
              " 'g': 49,\n",
              " 'h': 50,\n",
              " 'i': 51,\n",
              " 'j': 52,\n",
              " 'k': 53,\n",
              " 'l': 54,\n",
              " 'm': 55,\n",
              " 'n': 56,\n",
              " 'o': 57,\n",
              " 'p': 58,\n",
              " 'q': 59,\n",
              " 'r': 60,\n",
              " 's': 61,\n",
              " 't': 62,\n",
              " 'u': 63,\n",
              " 'v': 64,\n",
              " 'w': 65,\n",
              " 'x': 66,\n",
              " 'y': 67,\n",
              " 'z': 68}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "input_token_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0G0CJ1zwWNT",
        "outputId": "4b9f004e-7ada-4469-cd8a-b1a8fa903417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t': 0,\n",
              " '\\n': 1,\n",
              " ' ': 2,\n",
              " '!': 3,\n",
              " '\"': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '0': 9,\n",
              " '1': 10,\n",
              " '2': 11,\n",
              " '3': 12,\n",
              " '4': 13,\n",
              " '5': 14,\n",
              " '6': 15,\n",
              " '7': 16,\n",
              " '8': 17,\n",
              " ':': 18,\n",
              " '?': 19,\n",
              " 'A': 20,\n",
              " 'B': 21,\n",
              " 'C': 22,\n",
              " 'D': 23,\n",
              " 'E': 24,\n",
              " 'F': 25,\n",
              " 'G': 26,\n",
              " 'H': 27,\n",
              " 'I': 28,\n",
              " 'J': 29,\n",
              " 'K': 30,\n",
              " 'L': 31,\n",
              " 'M': 32,\n",
              " 'N': 33,\n",
              " 'O': 34,\n",
              " 'P': 35,\n",
              " 'Q': 36,\n",
              " 'R': 37,\n",
              " 'S': 38,\n",
              " 'T': 39,\n",
              " 'U': 40,\n",
              " 'V': 41,\n",
              " 'W': 42,\n",
              " 'Y': 43,\n",
              " 'a': 44,\n",
              " 'b': 45,\n",
              " 'c': 46,\n",
              " 'd': 47,\n",
              " 'e': 48,\n",
              " 'f': 49,\n",
              " 'g': 50,\n",
              " 'h': 51,\n",
              " 'i': 52,\n",
              " 'j': 53,\n",
              " 'k': 54,\n",
              " 'l': 55,\n",
              " 'm': 56,\n",
              " 'n': 57,\n",
              " 'o': 58,\n",
              " 'p': 59,\n",
              " 'q': 60,\n",
              " 'r': 61,\n",
              " 's': 62,\n",
              " 't': 63,\n",
              " 'u': 64,\n",
              " 'v': 65,\n",
              " 'w': 66,\n",
              " 'x': 67,\n",
              " 'y': 68,\n",
              " 'z': 69,\n",
              " '¡': 70,\n",
              " '«': 71,\n",
              " '»': 72,\n",
              " '¿': 73,\n",
              " 'Á': 74,\n",
              " 'É': 75,\n",
              " 'Ó': 76,\n",
              " 'Ú': 77,\n",
              " 'á': 78,\n",
              " 'é': 79,\n",
              " 'í': 80,\n",
              " 'ñ': 81,\n",
              " 'ó': 82,\n",
              " 'ú': 83,\n",
              " 'ü': 84}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "target_token_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "zB7uB7U46qQ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"    Creating 3 matrices containing only zeroes: encoder_input_data, decoder_input_data, decoder_target_data.\n",
        "\n",
        "    The shape of each matrix is equal to (len(input_texts), max_seq_length, num_tokens).\n",
        "\n",
        "    max_seq_length and num_tokens have different values for encoder and decoder.\"\"\"\n",
        "\n",
        "\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDNoNnEBMmFL"
      },
      "source": [
        "- **Replacing** the **zeroes** in the above matrices with **1** based on whether a character is **present** at that location or not.\n",
        "\n",
        "\n",
        "- This is similar to **one-hot-encoding** the features in **3** dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sMEgvDTYwWNW"
      },
      "outputs": [],
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    \n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        \n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnKhOxmFwWNZ",
        "outputId": "93039925-85e9-4ee4-d0b9-a35e32730d3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "encoder_input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "278hCGsVwWNb",
        "outputId": "4469790f-4e11-4443-e566-06964f40e2ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "decoder_input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeZziiyUwWNd",
        "outputId": "de29d1f3-8b74-4dea-9aac-3764694add8d",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "decoder_target_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcfbRmvaSI2W"
      },
      "source": [
        "**Observation:**\n",
        "\n",
        " - **Input Sequences**: Padded to a **maximum length** of **16** characters with a **vocabulary** of **69** different characters **(10000, 16, 69)**.\n",
        " \n",
        " - **Output Sequences**: Padded to a **maximum length** of **43** characters with a **vocabulary** of **85** different characters **(10000, 43, 85)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdxgqiTOQUiH"
      },
      "source": [
        "---\n",
        "<a name = Section6></a>\n",
        "# **6. Machine Translation Model with Attention Mechanism**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWnvjnqnMmEH"
      },
      "source": [
        "- We'll be using the following **process sequence** in this notebook:\n",
        "\n",
        "<br> \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/img0.png\"width=\"690\" height=\"350\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xmDsdjapjaL"
      },
      "source": [
        "<a name = Section11></a>\n",
        "### **6.1 Define Encoder Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNWNVbuUMmFb"
      },
      "source": [
        "- The **input** to the **encoder** is a sequence of **characters**, each encoded as **one-hot** vectors with length of **`num_encoder_tokens`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NmaYrUeoLMig"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens)) # Define an input sequence and process it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WGLRTfD5wWNi"
      },
      "outputs": [],
      "source": [
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs) \n",
        "\n",
        "#This returns the hidden state output returned by LSTM layers\n",
        "\n",
        "#as well as the hidden and cell state for all cells in the layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-d3FvnZMmFj"
      },
      "source": [
        "- We **discard `encoder_outputs`** and only keep the **states**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "78qIHwn2LppR"
      },
      "outputs": [],
      "source": [
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyCkU-HPUEG8"
      },
      "source": [
        "<a name = Section11></a>\n",
        "### **6.2 Define Decoder Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2XtnuUYwWNl"
      },
      "source": [
        "- The decoder **input** is defined as a **sequence** of **Spanish** characters one-hot **encoded** to binary vectors with a length of **`num_decoder_tokens`**.\n",
        "\n",
        "- The final **hidden** and **cell states** are ignored and only the **output** sequence of **hidden states** is referenced.\n",
        "\n",
        "- Importantly, the final **hidden** (state_h) & **cell** (state_c) state from the **encoder** is used to **initialize** the state of the **decoder**. \n",
        " \n",
        " - This means every time that the **encoder** model encodes an **input** sequence, the final **internal** states of the encoder model are **used** as the **starting point** for **outputting** the first character in the **output** sequence. \n",
        "  \n",
        " \n",
        " - This also means that the **encoder** and **decoder** layers must have the same **number** of cells, in this case, **256**.\n",
        "\n",
        "\n",
        "- A **Dense** output layer is used to **predict** each **character**.\n",
        "\n",
        " - This **Dense** layer is used to produce each **character** in the **output sequence** in a **one-shot** manner, rather than recursively, at **least** during training. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KvhgqerkLSco"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3gyFXwqHwWNl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\"\n",
        "    We set up our decoder to return full output sequences, and to return internal states as well.\n",
        "\n",
        "    We don't use the return states in the training model, but we will use them in inference.\n",
        "\n",
        "    Set up the decoder, using encoder_states as initial state.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAzNCg1DpjAs"
      },
      "source": [
        "<a name = Section11></a>\n",
        "### **6.3 Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxPeT-wwMmFw"
      },
      "source": [
        "- Define the **model** that will turn `encoder_input_data` & `decoder_input_data` to `decoder_target_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bCgzm9CQMmFy"
      },
      "outputs": [],
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "e_cAt8TIMmF1"
      },
      "outputs": [],
      "source": [
        "# Compiling the model.\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xPfePV8wWNp",
        "outputId": "0318074c-498a-49d9-bea6-24e37746dc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 12s 11ms/step - loss: 1.2774 - val_loss: 1.4284\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.2184 - val_loss: 1.4034\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.1953 - val_loss: 1.3710\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.1626 - val_loss: 1.3424\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.1292 - val_loss: 1.2671\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 1.0927 - val_loss: 1.2381\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 1.0592 - val_loss: 1.2257\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 1.0309 - val_loss: 1.1478\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 1.0019 - val_loss: 1.1894\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.9779 - val_loss: 1.1273\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 2s 10ms/step - loss: 0.9590 - val_loss: 1.1222\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.9402 - val_loss: 1.0844\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.9231 - val_loss: 1.0759\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.9090 - val_loss: 1.0680\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.8942 - val_loss: 1.0274\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.8803 - val_loss: 1.0601\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.8681 - val_loss: 1.0322\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.8573 - val_loss: 1.0095\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.8469 - val_loss: 1.0062\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.8377 - val_loss: 0.9873\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.8282 - val_loss: 0.9692\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.8188 - val_loss: 0.9704\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.8104 - val_loss: 0.9671\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 3s 10ms/step - loss: 0.8022 - val_loss: 0.9590\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.7952 - val_loss: 0.9503\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7876 - val_loss: 0.9375\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7803 - val_loss: 0.9333\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7736 - val_loss: 0.9296\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.7675 - val_loss: 0.9345\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.7607 - val_loss: 0.9153\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7548 - val_loss: 0.9235\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.7494 - val_loss: 0.9128\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7436 - val_loss: 0.9081\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7385 - val_loss: 0.9190\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7336 - val_loss: 0.8944\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.7286 - val_loss: 0.8965\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7240 - val_loss: 0.8926\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7193 - val_loss: 0.8856\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7149 - val_loss: 0.8848\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7101 - val_loss: 0.8841\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7059 - val_loss: 0.8803\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.7013 - val_loss: 0.8948\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.6976 - val_loss: 0.8762\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6934 - val_loss: 0.8783\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6893 - val_loss: 0.8743\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6859 - val_loss: 0.8719\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6820 - val_loss: 0.8719\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 2s 10ms/step - loss: 0.6779 - val_loss: 0.8629\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 2s 10ms/step - loss: 0.6742 - val_loss: 0.8609\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6707 - val_loss: 0.8631\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6682 - val_loss: 0.8694\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6646 - val_loss: 0.8615\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6620 - val_loss: 0.8559\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6589 - val_loss: 0.8567\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.6549 - val_loss: 0.8551\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6518 - val_loss: 0.8575\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6491 - val_loss: 0.8489\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6456 - val_loss: 0.8499\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6429 - val_loss: 0.8858\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6402 - val_loss: 0.8572\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6373 - val_loss: 0.8436\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.6345 - val_loss: 0.8581\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6320 - val_loss: 0.8521\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6291 - val_loss: 0.8498\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6271 - val_loss: 0.8536\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6237 - val_loss: 0.8470\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6218 - val_loss: 0.8532\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.6196 - val_loss: 0.8398\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6164 - val_loss: 0.8570\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 2s 10ms/step - loss: 0.6154 - val_loss: 0.8476\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6124 - val_loss: 0.8423\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6097 - val_loss: 0.8415\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6074 - val_loss: 0.8459\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.6054 - val_loss: 0.8470\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6032 - val_loss: 0.8414\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6012 - val_loss: 0.8426\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5987 - val_loss: 0.8404\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5961 - val_loss: 0.8412\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5942 - val_loss: 0.8496\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 2s 10ms/step - loss: 0.5919 - val_loss: 0.8650\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5900 - val_loss: 0.8377\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5876 - val_loss: 0.8392\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5868 - val_loss: 0.8382\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5840 - val_loss: 0.8402\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5826 - val_loss: 0.8337\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.5813 - val_loss: 0.8391\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.5797 - val_loss: 0.8428\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5781 - val_loss: 0.8318\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5761 - val_loss: 0.8380\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5742 - val_loss: 0.8323\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 2s 10ms/step - loss: 0.5731 - val_loss: 0.8453\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 3s 11ms/step - loss: 0.5701 - val_loss: 0.8503\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5689 - val_loss: 0.8392\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5669 - val_loss: 0.8369\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5656 - val_loss: 0.8328\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5644 - val_loss: 0.8313\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5636 - val_loss: 0.8372\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 3s 10ms/step - loss: 0.5618 - val_loss: 0.8334\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5590 - val_loss: 0.8385\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5592 - val_loss: 0.8426\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75a0475040>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Run training.\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
        "          batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igmhN1v-MmF7"
      },
      "source": [
        "- Creating a `weights` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "QuD0i-VOMmF7"
      },
      "outputs": [],
      "source": [
        "!mkdir weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7SXdnXLMmF-"
      },
      "source": [
        "- **Saving** the **model** in the `weights` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mmWRueJGMmF-"
      },
      "outputs": [],
      "source": [
        "model.save('weights/s2s.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKxb6QFApi4G"
      },
      "source": [
        "<a name = Section11></a>\n",
        "### **6.4 Inference Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqXeoGnFMmGB"
      },
      "source": [
        "\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/img7.png\"width=\"690\" height=\"350\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx8xqCAKwWNu"
      },
      "source": [
        "- Once the defined model is **fit**, it can be used to make **predictions**. \n",
        "\n",
        "- The **model** defined for training has learned **weights** for this operation, but the **structure** of the model is **not** designed to be called **recursively** to generate one **character** at a time.\n",
        "\n",
        "\n",
        "- Instead, new **models** are required for the **prediction** step:\n",
        "\n",
        "  - Specifically a model for **encoding English** input sequences of **characters**.\n",
        "\n",
        "  - A model that takes the sequence of **Spanish characters** generated so far and the **encoding** as **input** and **predicts** the next **character** in the sequence.\n",
        "\n",
        "- Defining the **inference** models requires **reference** to elements of the model used for **training** in the example. \n",
        "\n",
        "- Alternately, one could **define** a new model with the **same shapes** and **load** the **weights** from file.\n",
        "\n",
        "- The **encoder** model is defined as taking the **input layer** from the encoder in the trained model (**`encoder_inputs`**) and outputting the **hidden** and **cell state** tensors (**`encoder_states`**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StzUMfmCwWNw"
      },
      "source": [
        "#### Process of applying Inference Model\n",
        "\n",
        "1. **Encode** input and **retrieve** initial decoder state.\n",
        "  \n",
        "2. **Run** one step of decoder with this **initial state** and a start of **sequence** token as **target**.\n",
        "\n",
        "  - **Output** will be the **next target token**.\n",
        "  \n",
        "3. **Repeat** with the current **target** token and current states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tVG-MVAbwWNx"
      },
      "outputs": [],
      "source": [
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rzNqU8SRwWN1"
      },
      "outputs": [],
      "source": [
        "### The decoder requires the hidden and cell states from the encoder as the initial state of the newly defined encoder model. \n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GFjdkpakwWN4"
      },
      "outputs": [],
      "source": [
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "27HmE1ikwWN7"
      },
      "outputs": [],
      "source": [
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L25eMIs3MmGT"
      },
      "source": [
        "- **Reverse-lookup** token index to **decode sequences** back to something readable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "O99RF_arwWN9"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTHRgu5-Y3E2"
      },
      "source": [
        "**Observation:**\n",
        "\n",
        "- Both the **encoder** and **decoder** will be called **recursively** for each character that is to be generated in the **translated** sequence.\n",
        "\n",
        "- On the first call, the **hidden** and **cell** states from the encoder will be used to **initialize** the **decoder** LSTM layer, provided as **input** to the model directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TLaOZK4pwWN_"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDB-RnSvZLrq"
      },
      "source": [
        "**Observations:**\n",
        " - On subsequent recursive calls to the decoder, the **last hidden** and **cell state** must be provided to the model. \n",
        " \n",
        "  - These **state** values are already within the **decoder**. \n",
        "\n",
        "  - We must **re-initialize** the **state** on each call given the way that the model was **defined** in order to take the **final** states from the **encoder** on the first call.\n",
        "\n",
        " - Therefore, the **decoder** must **output** the hidden and cell **states** along with the **predicted character** on each call, so that these states can be assigned to a **variable** and used on each **subsequent** recursive call for a given **input** sequence of **English** text to be translated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2aWtpaMMmGZ"
      },
      "source": [
        "<a id=section605></a>\n",
        "### **6.5 Making Predictions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJmi-yzOMmGa"
      },
      "source": [
        "- Making **predictions** on the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUT4DyTxMmGa"
      },
      "source": [
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/img8.png\"length=\"350\"width=\"600\"/></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGECEV8awWOB",
        "outputId": "c63796b0-2290-48dd-82d4-1027a19ae937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 367ms/step\n",
            "1/1 [==============================] - 0s 339ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Este.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: ¡Corra\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: ¡Corra\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: ¡Corra\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: ¡Corra\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Corre.\n",
            "\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: ¿Quiéne\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: ¡Vena a a a Tom\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: ¡Auerto.\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: ¡Auerto.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: ¡Auerto.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: ¡Salo ara\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Salte.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: ¡Parae\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: ¡Parae\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: ¡Parae\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: ¡Coriento\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: ¡serento\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Vo tien.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Vo tien.\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: ¡Solo.\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Corre.\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Corre.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Lo puedo.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: ¡Esten anuento.\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: ¡Quin es es\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Somiro.\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: ¡Dispara.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Aorre esto.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: ¡Atara\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: ¡Atara\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: ¡Atara\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: ¡Atara\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: ¡Atara\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Sale.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va a lo.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: ¡Lo tento.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: ¡Lo perto.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: ¡Lo perto.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: He ran.\n",
            "Decoded sentence: Él corri.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Estena selon.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Ayrada.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Me can.\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: I know.\n",
            "Decoded sentence: Lo te aro.\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: I left.\n",
            "Decoded sentence: Toma.\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: I lied.\n",
            "Decoded sentence: Mente.\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: I lost.\n",
            "Decoded sentence: Sero.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: I quit.\n",
            "Decoded sentence: Sonte.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: I quit.\n",
            "Decoded sentence: Sonte.\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: I sang.\n",
            "Decoded sentence: Conri.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: I work.\n",
            "Decoded sentence: Estoy trabajar.\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: I'm 19.\n",
            "Decoded sentence: Estoy lesa.\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: I'm up.\n",
            "Decoded sentence: Estoy lesa.\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Escucha.\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Escucha.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Escucha.\n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡Ni en pesto\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: ¿La perdido.\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: ¿La perdido.\n",
            "\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "-\n",
            "Input sentence: Thanks.\n",
            "Decoded sentence: ¡rarcasa\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "-\n",
            "Input sentence: Thanks.\n",
            "Decoded sentence: ¡rarcasa\n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "-\n",
            "Input sentence: Try it.\n",
            "Decoded sentence: Pruébate a Tom.\n",
            "\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: We try.\n",
            "Decoded sentence: Lo preguntamos.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Lasata aso.\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Why me?\n",
            "Decoded sentence: ¿Por qué no.\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Ask Tom.\n",
            "Decoded sentence: Pregunta es con cana.\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Awesome!\n",
            "Decoded sentence: ¡La asto.\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Sen canta.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Be cool.\n",
            "Decoded sentence: Sea abuero.\n",
            "\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sé bueno.\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Be good.\n",
            "Decoded sentence: Se bueno.\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: Be good.\n",
            "Decoded sentence: Se bueno.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set) for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CYrBIRrThBJ"
      },
      "source": [
        "- **Validate** the **model** using our own example:\n",
        "\n",
        "  - Let's have the model translate something simple, like:\n",
        "\n",
        "    **\"How are you?\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTW2n5TKMmGe"
      },
      "source": [
        "- Creating a variable **`input_sentence`** consisting of the **input sentence** to be translated.\n",
        "\n",
        "\n",
        "- Creating **`test_sentence_tokenized`**, which is a 3 **dimensional** matrix of **zeroes** and filling zeroes with **1** if character is **present** at that location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meKBrD6aTkci",
        "outputId": "b1acad9d-e7a4-4c07-9fdd-31a9dbfc4f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How are you?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "¿Cómo está al lora\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_sentence = \"How are you?\"\n",
        "test_sentence_tokenized = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "for t, char in enumerate(input_sentence):\n",
        "    test_sentence_tokenized[0, t, input_token_index[char]] = 1.\n",
        "print(input_sentence)\n",
        "print(decode_sequence(test_sentence_tokenized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13zmsfALcd0j"
      },
      "source": [
        "----\n",
        "\n",
        "<a id=section7></a>\n",
        "# **7. Conclusion**\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnt9VAmUh6Fy"
      },
      "source": [
        "- Sequence to Sequence Model is used in various NLP Tasks like\n",
        "\n",
        "  - **Speech Recognition**\n",
        "\n",
        "  - **Machine Language Translation**\n",
        "\n",
        "  - **Name entity/Subject extraction**\n",
        "\n",
        "  - **Relation Classification**\n",
        "\n",
        "  - **Path Query Answering**\n",
        "\n",
        "  - **Speech Generation**\n",
        "\n",
        "  - **Chatbot**\n",
        "\n",
        "  - **Text Summarization**\n",
        "\n",
        "  - **Product Sales Forecasting**\n",
        "\n",
        "- The encoder **compressed** the whole source **sentence** into a **single** vector. This can very hard - the number of **possible meanings** of source is **infinite**. When the **encoder** is forced to put all **information** into a single vector, it is likely to **forget** something.\n",
        "\n",
        "- - Encoder's final **hidden states**, along with the **start-of-sequence** character, were used as **input** for the **decoder**.\n",
        "\n",
        "- Each **predicted** character was then **fed** back into the **decoder** while the hidden states were updated. \n",
        "\n",
        "- We **repeated** this until the **decoder** predicted the **end-of-sequence** character **telling** us the **predicted** sequence is complete.\n",
        "\n",
        "- Techniques like **Beam Search**, **Attention Mechanism** can be used to improve performence of Seq2seq Models."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "307.2px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}