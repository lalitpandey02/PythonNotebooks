{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalitpandey02/PythonNotebooks/blob/main/2_What_is_a_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA6Qe6oaeD-V"
      },
      "source": [
        "<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"100\" /></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJMDQ4Ro7-zF"
      },
      "source": [
        "<center><h1>Generative Adversarial Network</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdM1B2wmaVYA"
      },
      "source": [
        "---\n",
        "# **Table of Contents**\n",
        "---\n",
        "\n",
        "**1.** [**Introduction**](#section1)<br>\n",
        "**2.** [**Generative Model vs Discriminative Model**](#section2)<br>\n",
        "**3.** [**Why were GANs developed in the first place?**](#section3)<br>\n",
        "**4.** [**How does GANs work?**](#section4)<br>\n",
        "**5.** [**Training a GAN**](#section5)<br>\n",
        "**6.** [**Different Types of GAN**](#section6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl3nUYzS8UCk"
      },
      "source": [
        "---\n",
        "<a name = Section1></a>\n",
        "# **1. Introduction**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I3z-YOXaVYC"
      },
      "source": [
        "- In **supervised learning**, we have data **'X'** and respone (label) **'Y'** and the goal is to learn a function to map x to y e.g. **regression**, **classification**, **object detection**.\n",
        "\n",
        "- In **unsupervised learning**, there are no labels and the goal is to find some underlying hidden structures of the data e.g. **clustering**, **dimesnionality reduction**, **feature learning**.\n",
        "\n",
        "- The **goal** of generative models is to **generate new samples** of data from a distribution.\n",
        "\n",
        "  - These models are used in problems such as **density estimation**, a problem of unsupervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbpAogRoaVYD"
      },
      "source": [
        "- Generative Adversarial Networks (GANs) is a **powerful** class of neural **networks** that are used for **unsupervised learning**.\n",
        "\n",
        "  - It was developed and introduced by Ian J.Goodfellow in 2014.\n",
        "\n",
        "  - Basically made up of a system of **two competing** neural network models which compete with **each** other and are able to **analyze**, **capture** and **copy** the **variations** within a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpVQG5UVaVYI"
      },
      "source": [
        "---\n",
        "<a name = Section2></a>\n",
        "# **2. Generative Model vs Discriminative Model**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4cN04ZxaVYJ"
      },
      "source": [
        "- The **discriminative** models learn the **conditional probability** distribution **P(y|x)** i. e. the **decision** boundary between classes e. g. Logistic Regression, Neural Network.\n",
        "\n",
        "- The Generatice models learn the **joint probability** distribution **P(x|y)** i. e. the **distribution** of individual classes e. g. Naive Bayes, Gaussian Discriminant Analysis (GDA).\n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/g.png\" width=\"500\" height=\"320\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_ZQtnM2aVYK"
      },
      "source": [
        "---\n",
        "<a name = Section3></a>\n",
        "# **3. Why were GANs developed in the first place?**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnWAAJrmaVYK"
      },
      "source": [
        "- Most of the **mainstream** neural nets can be easiy fooled into **misclassifying things** by adding only a small amount of **noise** into the original data.\n",
        "\n",
        "- Surprisingly, the model **after** adding noise has **higher confidence** in the wrong **prediction** than when it predicted **correctly**.\n",
        "\n",
        "- The reason for such **adversary** is that most machine learning models learn from a **limited** amount of data, which is a huge drawback, as they are **prone to overfitting**.\n",
        "\n",
        "- Mapping between the **input** and **output** is almost **linear**.\n",
        "\n",
        "- Although, it may seem that the **boundaries of seperation** between the various classes are **linear**, but in reality, they are composed of linearities and even a **small change** in a point in the **feature** space might lead to **misclassification** of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk72WlydaVYL"
      },
      "source": [
        "#### **Let's understand using an example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bySyaBWPaVYM"
      },
      "source": [
        "- Consider a example of the process of money **counterfeiting**.\n",
        "\n",
        "- In this process, we can imagine, two types of **agents**:\n",
        "\n",
        "  - **A Criminal**\n",
        "\n",
        "  - **A Cop**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTAs_FA8aVYN"
      },
      "source": [
        "-  Let's look their competing objectives.\n",
        "\n",
        "  - **Criminal's Objective:** The main objective of the **criminal** is to come up with complex ways of **counterfeiting** money such that the **Cop** cannot distinguish between counterfeited money and **real money**.\n",
        "\n",
        "  - **Cop's Objective:** The main objective of the cop is to come up with **complex** ways so as to **distinguish** between counterfeited money and real money."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gaccrsqaVYO"
      },
      "source": [
        "- As this progresses the **cop** develops more and more **sophisticated** technology to detect money counterfeiting and **criminal** develops more and more sophisticated technology to **counterfeit money**.\n",
        "\n",
        "- This is the basis of what is called an **Adversarial Process**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vrpHbv6aVYP"
      },
      "source": [
        "---\n",
        "<a name = Section4></a>\n",
        "# **4. How does GANs work?**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q4GZYFsaVYQ"
      },
      "source": [
        "- The **underlying** idea is to use **two** neural networks instead of one.\n",
        "\n",
        "- The training and learning process stay the **same** and **utilize** the standard techniques (like **backpropagation**).\n",
        "\n",
        "- However, this time we train not one, but two models:\n",
        "\n",
        "  - **A Generative Model (G)** and,\n",
        "\n",
        "  - **A Discriminative Model** (D)\n",
        "\n",
        "- Generative Adversarial Networks can be broken down into **three parts**:\n",
        "\n",
        "  - **Generative**: To learn a generative model, which describes how data is generated in terms of a **probabilistic model**.\n",
        "\n",
        "  - **Adversarial**: The **training** of a model is done in an **adversarial setting**.\n",
        "\n",
        "  - **Networks**: Use deep neural networks as the Artificial Intelligence(AI) algorithms for **training purpose**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7RvdHueaVYQ"
      },
      "source": [
        "- In GANs, there is a **Generator** and a **Discriminator**.\n",
        "\n",
        "  - The **Generator** generates **fake sample** of data (be it an image, audio, etc.) and **tries to fool** the Discriminator.\n",
        "\n",
        "  - The **Discriminator**, on the other hand, tries to **distinguish** between the **real and fake samples**.\n",
        "\n",
        "  - The Generator and Discriminator are both **Neural Networks** and they both run in **competition** with each other in the **training phase**.\n",
        "\n",
        "  - The steps are **repeated** several times and in this, the Generator and Discriminator get **better and better** in their respective jobs after **each repetition**.\n",
        "\n",
        "<br> \n",
        "- **Check the below flowchart:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fPzh4InaVYS"
      },
      "source": [
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/gan1.jpg\" width=\"900\" height=\"500\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "insAk3gyaVYS"
      },
      "source": [
        "#### **Understanding it's working**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE7kbag1aVYT"
      },
      "source": [
        "- Here, \n",
        "\n",
        "  - The Generative model **captures** the **distribution** of data and is trained in such a manner that it tries to **maximize** the **probability** of the **Discriminator** in making a **mistake**.\n",
        "\n",
        "  - The Discriminator, on the other hand, is based on a model that **estimates** the **probability** that the sample that it got is received from the training data and not from the Generator.\n",
        "\n",
        "  - The GANs are formulated as a **minimax** game, where the Discriminator is trying to **maximize** its reward **V(D, G)** and the Generator is trying to **minimize** the Discriminator's **reward** or in other words, maximize its loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6cgBoT9aVYU"
      },
      "source": [
        "- **Mathematically**,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djvkqcRmaVYV"
      },
      "source": [
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/gan2.png\" width=\"600\" height=\"110\"><center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQT-k3bcaVYW"
      },
      "source": [
        "- **where**,\n",
        "\n",
        "  - $G$ = Generator\n",
        "\n",
        "  - $D$ = Discriminator\n",
        "\n",
        "  - $P_{data}(x)$ = Distribution of original data\n",
        "\n",
        "  - $P_{z}(z)$ = Distribution of input noise\n",
        "\n",
        "  - $x$ = Sample from $P_{data}(x)$\n",
        "\n",
        "  - $z$ = Sample from $P_{z}(z)$\n",
        "\n",
        "  - $D(x)$ = Discriminator network\n",
        "\n",
        "  - $G(z)$ = Generator network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGWqwbkPaVYW"
      },
      "source": [
        "---\n",
        "<a name = Section5></a>\n",
        "# **5. Training a GAN**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjc4eV8QaVYX"
      },
      "source": [
        "- **GAN Network**\n",
        "\n",
        "<br> \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/g1.png\" width=\"600\" height=\"220\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nTbiuAdaVYY"
      },
      "source": [
        "<br> \n",
        "- Training a GAN has **two parts**.\n",
        "\n",
        "- Training involves **alternating** between training the discriminator and the generator.\n",
        "\n",
        "- The **real loss** and **fake loss** are used to calculate the **discriminator** losses as follows:\n",
        "\n",
        "<br> \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/g2.png\" width=\"600\" height=\"320\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykBG4kgoaVYZ"
      },
      "source": [
        "- **Part 1**:\n",
        "\n",
        "  - The **Discriminator** is **trained** while the **Generator** is **idle**.\n",
        "\n",
        "  - In this phase, the network is **only forward propagated** and no **back-propagaton** is done.\n",
        "\n",
        "  - The Discriminator is **trained** on real data for **n epochs** and see if it can correctly **predict** them as real.\n",
        "\n",
        "  - In this phase, the **Discriminator** is also trained on the **fake generated** data from the Generator and see if it can correctly **predict** them as fake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBjJf-IFaVYa"
      },
      "source": [
        "- **Part 2**:\n",
        "\n",
        "  - The **Generator** is **trained** while the **Discriminator** is **idle**.\n",
        "\n",
        "  - After the Disciminator is trained by the generated fake data of the Generator, we can get its predictions and use the results for training the Generator and get better from the previous state to try and fool the Discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o-BK96TaVYb"
      },
      "source": [
        "- The above method is **repeated** for a **few epochs** and then *manually check the fake data* to see if it seems **genuine**.\n",
        "\n",
        "- If it seems **acceptable**, then the **training** is **stopped**, otherwise, its allowed to continue for few more epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65gS9lseaVYc"
      },
      "source": [
        "#### **Discriminator (D) Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flpbTQMgaVYc"
      },
      "source": [
        "- For the real images, we want **D(real images) = 1**.\n",
        "\n",
        "  - This means we want the **discriminator** to classify the **real images** with a label = 1, indicating that these are real.\n",
        "\n",
        "- The discriminator **loss** for the fake data is **similar**.\n",
        "\n",
        "  - We want **D(fake images) = 0**, where the fake images are the generator output, **fake_images = G(z)**.\n",
        "\n",
        "- Steps:\n",
        "\n",
        "  1. Compute the **discriminator loss** on real, training images.\n",
        "\n",
        "  2. **Generate** fake images.\n",
        "\n",
        "  3. Compute the discriminator loss on fake, **generated images**.\n",
        "\n",
        "  4. Add up **real and fake** loss to get total loss.\n",
        "\n",
        "  5. Perform **backpropagation** + an **optimization** step to update the discriminator's weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e8EvmZQaVYd"
      },
      "source": [
        "#### **Generator (G) Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trholyMZaVYe"
      },
      "source": [
        "- The generator's goal is to get **D(fake images) = 1**.\n",
        "\n",
        "  1. Generate **fake** images.\n",
        "\n",
        "  2. Compute the discriminator loss on fake images, using **flipped labels**.\n",
        "\n",
        "  3. Perform **backpropagation + an optimization** step to update the generator's weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLo3nZPlaVYf"
      },
      "source": [
        "---\n",
        "<a name = Section6></a>\n",
        "# **6. Different Types of GAN**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fuBLXsFaVYf"
      },
      "source": [
        "- GANs are now a very active topics of **research** and there have been many different types of **GAN implementation**.\n",
        "\n",
        "- Some of the important ones that are actively being used currently are described below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkJegOxraVYg"
      },
      "source": [
        "- **Vanilla GAN**\n",
        "\n",
        "  - This is the **simplest** type GAN.\n",
        "\n",
        "  - The Generator and the Discriminator are simple **multi-layer perceptrons**.\n",
        "\n",
        "  - In Vanilla GAN, the algorithm is really simple, it tries to **optimize** the mathematical equation using **stochastic gradient** **descent**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZUC58C_aVYh"
      },
      "source": [
        "- **Conditional GAN (CGAN)**\n",
        "\n",
        "  - CGAN can be described as a deep learning method in which some **conditional** **parameters** are put into place.\n",
        "\n",
        "  - An additional parameter **`y`** is added to the Generator for **generating** the corresponding data.\n",
        "\n",
        "  - **Labels** are also put into the input to the Discriminator in order for the Discriminator to help **distinguish** the **real data** from the fake generated data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsilV1mjaVYi"
      },
      "source": [
        "- **Deep Convolutional GAN (DCGAN)**\n",
        "\n",
        "  - DCGAN is one of the most popular also the most **successful** implementation of GAN.\n",
        "\n",
        "  - It is composed of **ConvNets** in place of **multi-layer perceptrons**.\n",
        "\n",
        "  - The ConvNets are implemented without **max pooling**, which is in fact replaced by convolutional **stride**.\n",
        "\n",
        "  - The layers are **not fully** connected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMM4u6vVaVYj"
      },
      "source": [
        "- **Laplacian Pyramid GAN (LAPGAN)**\n",
        "\n",
        "  - Laplacian pyramid is **linear ivertible** image representation consisting of a set of band-pass images, spaced an **octave** apart, plus a **low-frequency** residual.\n",
        "\n",
        "  - This uses **multiple** numbers of Generator and Discriminator networks and different levels of the **Laplacian Pyramid**.\n",
        "\n",
        "  - Used mainly because it produces very **high-quality images**.\n",
        "\n",
        "  - The image is **downsampled** at first at each layer of the **pyramid** and then it is again up-scaled at each layer in a **backward pass** where the image acquires some noise from the **Conditional** GAN at these layers until it **reaches** its original size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI4200TcaVYk"
      },
      "source": [
        "- **Super Resolution GAN (SRGAN)**\n",
        "\n",
        "  - As the name suggests is a way of **designing** GAN in which a **deep** neural network is used along with an **adversarial** network in order to **produce** higher resolution images.\n",
        "\n",
        "  - This type of GAN is particularly useful in **optimally** **up-scaling** native low-resolution images to **enhance** their details and minimizing **errors** while doing so."
      ]
    }
  ]
}